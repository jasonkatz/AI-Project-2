Jason Katz
ECE-469 Project 2: Neural Network

Neural network implementation
with one hidden layer

Write Up

The data used to test this network describes final states of the game tic tac toe.
There are 9 input attributes, each corresponding to a square on the tic tac toe board,
and 1 output class which indicates a positive or negative result for 'x'
(win = positive, loss/draw = negative). The neural network was tested with various
training parameters, but what seemed to work the best was a network with 20 nodes
in the hidden layer, 1000 epochs and a learning rate of .5. Training is done by a C++
program train.cpp, and testing is done by a C++ program test.cpp.
The initial network used has pseudo-randomly generated weights on all of the links 
between 0 and 1, and is contained in ttt.init. The training set file is ttt.train 
and the testing set file is ttt.test. The trained neural network file is ttt.trained. 
The results for the most reasonable outcome (using parameters described above) are 
stored in results.txt. Some more trial data can be found in info.txt.
The data was obtained from the UC Irvine Machine Learning Repository, and can be found
at http://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame (also in ttt.data). The data
was processed into training and testing sets by a C++ program tttParse.cpp, which either
selects odd row data or even row data depending on whether a training set or testing set is
desired. Each square is given a value (0.000 for blank, 0.500 for x and 1.000 for o), and the
results are given a binary value (0 for negative and 1 for positive).
The initial neural network was generated by a C++ program tttInit, which creates a
.init file with a specified number of nodes in the hidden layer (9 inputs and 1 output,
as per the spec of the problem).
Data parsing, network initialization, network training, and network testing all have
corresponding make targets parse, init, train, and test, respectively.